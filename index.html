<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>OCR & Translate SPA</title>
  <style>
    body { font-family: sans-serif; padding: 16px; }
    video { width: 100%; max-width: 400px; }
    pre { background: #f4f4f4; padding: 8px; min-height: 2em; }
    button { margin-top: 8px; margin-right: 8px; }
    #canvas { display: none; }
  </style>
  <!-- Tesseract.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tesseract.js/2.1.5/tesseract.min.js"></script>
</head>
<body>
  <h1>OCR & Translate в браузере</h1>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <div>
    <button id="scanBtn">Сканировать текст</button>
    <button id="translateBtn" disabled>Перевести</button>
  </div>

  <h2>Оригинал (англ.):</h2>
  <pre id="original">—</pre>
  <h2>Перевод (рус.):</h2>
  <pre id="translated">—</pre>

  <script>
    const video = document.getElementById('video');
    const originalEl = document.getElementById('original');
    const translatedEl = document.getElementById('translated');
    const scanBtn = document.getElementById('scanBtn');
    const translateBtn = document.getElementById('translateBtn');

    let lastText = ''; // сюда сохраняем результат OCR

    // Старт камеры (задняя)
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { exact: "environment" } },
          audio: false
        });
        video.srcObject = stream;
      } catch {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
          audio: false
        });
        video.srcObject = stream;
      }
    }
    startCamera();

    // Функция распознавания
    async function doOCR() {
      scanBtn.disabled = true;
      originalEl.textContent = 'Распознавание...';
      translatedEl.textContent = '—';
      translateBtn.disabled = true;

      // снимок кадра
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const dataURL = canvas.toDataURL('image/png');

      // OCR
      const { createWorker } = Tesseract;
      const worker = createWorker();
      await worker.load();
      await worker.loadLanguage('eng');
      await worker.initialize('eng');
      const { data: { text } } = await worker.recognize(dataURL);
      await worker.terminate();

      lastText = text.trim();
      originalEl.textContent = lastText || 'Не удалось распознать текст';
      scanBtn.disabled = false;
      translateBtn.disabled = !lastText;
    }

    // Функция перевода через Google Translate unofficial endpoint
    async function doTranslate() {
      if (!lastText) return;
      translateBtn.disabled = true;
      translatedEl.textContent = 'Перевод...';

      try {
        const url = 
          'https://translate.googleapis.com/translate_a/single?client=gtx' +
          '&sl=en&tl=ru&dt=t&q=' + encodeURIComponent(lastText);

        const response = await fetch(url);
        if (!response.ok) throw new Error('HTTP ' + response.status);
        const data = await response.json();

        // data[0] — массив предложений, каждый элемент [перевод, оригинал, ...]
        const translated = data[0].map(item => item[0]).join(' ');
        translatedEl.textContent = translated || 'Пустой результат перевода';
      } catch (e) {
        translatedEl.textContent = 'Ошибка перевода: ' + e.message;
      } finally {
        translateBtn.disabled = false;
      }
    }

    scanBtn.addEventListener('click', doOCR);
    translateBtn.addEventListener('click', doTranslate);
  </script>
</body>
</html>
